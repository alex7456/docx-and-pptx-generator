import wikipedia
import re
import json
import requests
import urllib.parse
from io import BytesIO
from bs4 import BeautifulSoup
from docx import Document
from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.enum.text import PP_PARAGRAPH_ALIGNMENT
from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM
import dash
from dash import dcc, html, Input, Output, State
import dash_bootstrap_components as dbc
from pptx.dml.color import RGBColor
from pptx.enum.text import MSO_ANCHOR


wikipedia.set_lang("ru")
summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])
server = app.server

TOPIC_TRANSLATIONS = {
    "–≥–æ—Ä—ã": "mountains", "–∫–æ—Å–º–æ—Å": "space", "–º–æ—Ä–µ": "sea", "–æ–∫–µ–∞–Ω": "ocean",
    "–∂–∏–≤–æ—Ç–Ω—ã–µ": "animals", "—á–µ–ª–æ–≤–µ–∫": "human", "–ø—Ä–∏—Ä–æ–¥–∞": "nature", "–≥–æ—Ä–æ–¥": "city",
    "–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞": "architecture", "–∏—Å—Ç–æ—Ä–∏—è": "history", "—Ç–µ—Ö–Ω–∏–∫–∞": "technology",
    "–Ω–∞—É–∫–∞": "science", "–º—É–∑—ã–∫–∞": "music", "—Å–ø–æ—Ä—Ç": "sport", "–µ–¥–∞": "food"
}

def get_clean_article(title):
    try:
        page = wikipedia.page(title)
        text = page.content
        text = re.split(r"==\s*–°–º\. —Ç–∞–∫–∂–µ\s*==", text)[0]
        text = re.sub(r"==+\s*(.*?)\s*==+", r"¬ß\1¬ß", text)
        return text.strip()
    except:
        return None

def split_into_sections(text, max_sections):
    sections = []
    parts = re.split(r'¬ß(.*?)¬ß', text)
    for i in range(1, len(parts), 2):
        title = parts[i].strip()
        content = parts[i + 1].strip()
        sections.append((title, content))
    return sections[:max_sections]

def chunk_text_to_bullets(text, max_lines=4):
    sentences = re.split(r'(?<=[.!?])\s+', text.strip())
    return [s.strip() for s in sentences if len(s.strip()) > 20][:max_lines]

def fetch_image_urls_bing(query, count):
    search_term = TOPIC_TRANSLATIONS.get(query.lower(), query)
    headers = {"User-Agent": "Mozilla/5.0"}
    url = f"https://www.bing.com/images/search?q={urllib.parse.quote(search_term)}"

    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.text, "html.parser")
    image_tags = soup.find_all("a", class_="iusc")

    urls = []
    for tag in image_tags:
        try:
            m_json = json.loads(tag.get("m"))
            img_url = m_json["murl"]
            if "ytimg.com" in img_url or "youtube" in img_url:
                continue
            if img_url.endswith((".jpg", ".jpeg", ".png")):
                urls.append(img_url)
            if len(urls) >= count:
                break
        except:
            continue
    return urls

try:
    summarizer = pipeline(
        "summarization",
        model="IlyaGusev/rut5_base_sum_gazeta",
        tokenizer="IlyaGusev/rut5_base_sum_gazeta"
    )
except:
    # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∑–∏—Ç—Å—è
    summarizer = None

def smart_conclusion(title, sections):
    print("üß† –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ...")
    
    # –í–∞—Ä–∏–∞–Ω—Ç—ã –∑–∞–∫–ª—é—á–µ–Ω–∏–π –Ω–∞ —Å–ª—É—á–∞–π –æ—à–∏–±–æ–∫
    FALLBACK_CONCLUSIONS = [
        "–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥ –æ –≤–∞–∂–Ω–æ—Å—Ç–∏ –∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω–æ–π —Ç–µ–º—ã.",
        "–ü—Ä–æ–≤–µ–¥–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ–∑–≤–æ–ª—è–µ—Ç —É—Ç–≤–µ—Ä–∂–¥–∞—Ç—å, —á—Ç–æ —ç—Ç–∞ —Ç–µ–º–∞ –∑–∞—Å–ª—É–∂–∏–≤–∞–µ—Ç –æ—Å–æ–±–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è.",
        "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–Ω–∞—è —Ç–µ–º–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –Ω–∞—É—á–Ω—ã–π –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä–µ—Å.",
        "–ò–∑—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω–æ–π —Ç–µ–º—ã –ø–æ–∑–≤–æ–ª—è–µ—Ç –ª—É—á—à–µ –ø–æ–Ω—è—Ç—å –∫–ª—é—á–µ–≤—ã–µ –∞—Å–ø–µ–∫—Ç—ã —ç—Ç–æ–π –æ–±–ª–∞—Å—Ç–∏ –∑–Ω–∞–Ω–∏–π."
    ]
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –≤—Å–µ—Ö —Ä–∞–∑–¥–µ–ª–æ–≤
    combined = "\n".join([f"{sec[0]}: {sec[1]}" for sec in sections if len(sec[1].strip()) > 30])
    
    # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ —Å–æ–≤—Å–µ–º –º–∞–ª–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
    if len(combined) < 200:
        return FALLBACK_CONCLUSIONS[0]
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç
    clean_text = ' '.join(combined.replace("\n", " ").split())
    
    # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
    if summarizer is None:
        return FALLBACK_CONCLUSIONS[1]
    
    try:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–ª—é—á–µ–≤—ã–µ –ø—É–Ω–∫—Ç—ã
        key_points = summarizer(
            clean_text,
            max_length=150,
            min_length=50,
            do_sample=False,
            truncation=True
        )[0]['summary_text']
        
        # –ù–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö –ø—É–Ω–∫—Ç–æ–≤ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∑–∞–∫–ª—é—á–µ–Ω–∏–µ
        conclusion = summarizer(
            f"–ö–ª—é—á–µ–≤—ã–µ –ø—É–Ω–∫—Ç—ã: {key_points}. –ù–∞–ø–∏—à–∏ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞—É—á–Ω–æ–≥–æ –¥–æ–∫–ª–∞–¥–∞.",
            max_length=120,
            min_length=60,
            do_sample=False,
            truncation=True
        )[0]['summary_text']
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if len(conclusion) > 20 and "." in conclusion:
            return conclusion
        else:
            return FALLBACK_CONCLUSIONS[2]
            
    except Exception as e:
        print(f"‚ö† –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}")
        return FALLBACK_CONCLUSIONS[3]

def generate_report(title, intro, sections, conclusion):
    doc = Document()
    doc.add_heading(title, 0)

    doc.add_heading("–í–≤–µ–¥–µ–Ω–∏–µ", level=1)
    doc.add_paragraph(intro)

    doc.add_heading("–û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å", level=1)
    for sec_title, sec_text in sections:
        doc.add_heading(sec_title, level=2)
        doc.add_paragraph(sec_text)

    doc.add_heading("–ó–∞–∫–ª—é—á–µ–Ω–∏–µ", level=1)
    final_thought = smart_conclusion(title, sections)
    if len(final_thought) < 30:  # –ï—Å–ª–∏ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ
        final_thought = "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–Ω–∞—è —Ç–µ–º–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –≤–∞–∂–Ω—ã–π –∞—Å–ø–µ–∫—Ç –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è."

    doc.add_paragraph(final_thought)

    filename = f"{title}_report.docx"
    doc.save(filename)


def split_text_on_slides(text, max_characters=800):
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–µ–π, –µ—Å–ª–∏ –æ–Ω –ø—Ä–µ–≤—ã—à–∞–µ—Ç –∑–∞–¥–∞–Ω–Ω—ã–π –ª–∏–º–∏—Ç –ø–æ —Å–∏–º–≤–æ–ª–∞–º.
    """
    slides = []
    while len(text) > max_characters:
        split_point = text.rfind(" ", 0, max_characters)  # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø—Ä–æ–±–µ–ª –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –ª–∏–º–∏—Ç–∞
        slides.append(text[:split_point].strip())  # –î–æ–±–∞–≤–ª—è–µ–º —á–∞—Å—Ç—å —Ç–µ–∫—Å—Ç–∞
        text = text[split_point:].strip()  # –û—Å—Ç–∞–≤—à–∏–π—Å—è —Ç–µ–∫—Å—Ç
    slides.append(text)  # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —á–∞—Å—Ç—å —Ç–µ–∫—Å—Ç–∞
    return slides

def generate_presentation(title, intro, sections, conclusion, image_urls):
    prs = Presentation()

    # –°–ª–∞–π–¥ —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
    slide = prs.slides.add_slide(prs.slide_layouts[0])
    slide.shapes.title.text = title
    slide.placeholders[1].text = "–ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è –ø–æ —Ç–µ–º–µ"

    # –í–≤–µ–¥–µ–Ω–∏–µ: —Ä–∞–∑–¥–µ–ª—è–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É –∏ —Ç–µ–∫—Å—Ç
    slide = prs.slides.add_slide(prs.slide_layouts[5])  # –ò—Å–ø–æ–ª—å–∑—É–µ–º layout —Å –ø—É—Å—Ç—ã–º–∏ –ø–æ–ª—è–º–∏
    slide.shapes.title.text = "–í–≤–µ–¥–µ–Ω–∏–µ"
    slide.background.fill.solid()  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–æ–Ω —Å–ª–∞–π–¥–∞
    slide.background.fill.fore_color.rgb = RGBColor(200, 220, 255)  # –°–∏–Ω–∏–π –æ—Ç—Ç–µ–Ω–æ–∫

    # –¢–µ–∫—Å—Ç
    tf = slide.shapes.add_textbox(Inches(1), Inches(1.5), Inches(5), Inches(5))
    text_frame = tf.text_frame
    text_frame.word_wrap = True  # –í–∫–ª—é—á–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ–Ω–æ—Å —Ç–µ–∫—Å—Ç–∞
    p = text_frame.add_paragraph()
    p.text = intro
    p.font.size = Pt(18)
    text_frame.text_anchor = MSO_ANCHOR.TOP  # –ß—Ç–æ–±—ã —Ç–µ–∫—Å—Ç –Ω–µ —Å–∂–∏–º–∞–ª—Å—è –≤–Ω–∏–∑—É

    # –ö–∞—Ä—Ç–∏–Ω–∫–∞
    if image_urls:
        try:
            response = requests.get(image_urls[0])
            if response.status_code == 200 and "image" in response.headers.get("Content-Type", ""):
                img_stream = BytesIO(response.content)
                slide.shapes.add_picture(img_stream, Inches(0.5), Inches(4.5), height=Inches(3), width=Inches(3))
        except:
            pass

    # –û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å
    for i, (sec_title, sec_text) in enumerate(sections):
        slide = prs.slides.add_slide(prs.slide_layouts[5])  # –°–ª–∞–π–¥ —Å –ø—É—Å—Ç—ã–º–∏ –ø–æ–ª—è–º–∏
        slide.shapes.title.text = sec_title
        slide.background.fill.solid()
        slide.background.fill.fore_color.rgb = RGBColor(255, 255, 200)  # –°–≤–µ—Ç–ª–æ-–∂–µ–ª—Ç—ã–π —Ñ–æ–Ω

        # –¢–µ–∫—Å—Ç
        tf = slide.shapes.add_textbox(Inches(1), Inches(1.5), Inches(5), Inches(5))
        text_frame = tf.text_frame
        text_frame.word_wrap = True  # –í–∫–ª—é—á–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ–Ω–æ—Å —Ç–µ–∫—Å—Ç–∞
        p = text_frame.add_paragraph()
        p.text = sec_text
        p.font.size = Pt(18)
        text_frame.text_anchor = MSO_ANCHOR.TOP  # –ß—Ç–æ–±—ã —Ç–µ–∫—Å—Ç –Ω–µ —Å–∂–∏–º–∞–ª—Å—è –≤–Ω–∏–∑—É

        # –ö–∞—Ä—Ç–∏–Ω–∫–∞
        if i < len(image_urls):
            try:
                response = requests.get(image_urls[i])
                if response.status_code == 200 and "image" in response.headers.get("Content-Type", ""):
                    img_stream = BytesIO(response.content)
                    slide.shapes.add_picture(img_stream, Inches(0.5), Inches(4.5), height=Inches(3), width=Inches(3))
            except:
                pass

    # –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
    slide = prs.slides.add_slide(prs.slide_layouts[5])  # –°–ª–∞–π–¥ —Å –ø—É—Å—Ç—ã–º–∏ –ø–æ–ª—è–º–∏
    slide.shapes.title.text = "–ó–∞–∫–ª—é—á–µ–Ω–∏–µ"
    slide.background.fill.solid()
    slide.background.fill.fore_color.rgb = RGBColor(255, 230, 230)  # –†–æ–∑–æ–≤—ã–π —Ñ–æ–Ω

    # –¢–µ–∫—Å—Ç
    tf = slide.shapes.add_textbox(Inches(1), Inches(1.5), Inches(5), Inches(5))
    text_frame = tf.text_frame
    text_frame.word_wrap = True  # –í–∫–ª—é—á–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ–Ω–æ—Å —Ç–µ–∫—Å—Ç–∞
    p = text_frame.add_paragraph()
    p.text = conclusion
    p.font.size = Pt(18)
    text_frame.text_anchor = MSO_ANCHOR.TOP  # –ß—Ç–æ–±—ã —Ç–µ–∫—Å—Ç –Ω–µ —Å–∂–∏–º–∞–ª—Å—è –≤–Ω–∏–∑—É

    filename = f"{title}_presentation.pptx"
    prs.save(filename)

app.layout = dbc.Container([
    html.H2("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–æ–∫–ª–∞–¥–∞ –∏ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏"),
    dbc.Row([
        dbc.Col([
            html.Label("–¢–µ–º–∞"),
            dcc.Input(id="topic", type="text", value="–ö–æ—Å–º–æ—Å", style={"width": "100%"}),
            html.Br(), html.Br(),
            html.Label("–ß—Ç–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å:"),
            dcc.RadioItems(
                id="mode", options=[
                    {"label": "–î–æ–∫–ª–∞–¥", "value": "report"},
                    {"label": "–ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è", "value": "presentation"},
                    {"label": "–û–±–∞", "value": "both"},
                ],
                value="both",
                labelStyle={'display': 'block'}
            ),
            html.Label("–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞:"),
            dcc.Dropdown(
                options=[
                    {"label": "–ö—Ä–∞—Ç–∫–∏–π", "value": "–∫—Ä–∞—Ç–∫–∏–π"},
                    {"label": "–°—Ä–µ–¥–Ω–∏–π", "value": "—Å—Ä–µ–¥–Ω–∏–π"},
                    {"label": "–ü–æ–¥—Ä–æ–±–Ω—ã–π", "value": "–ø–æ–¥—Ä–æ–±–Ω—ã–π"}
                ],
                value="—Å—Ä–µ–¥–Ω–∏–π",
                id="detail"
            ),
            html.Label("–°–ª–∞–π–¥–æ–≤ (–µ—Å–ª–∏ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è):"),
            dcc.Input(id="slides", type="number", value=8, min=5, max=15),
            html.Label("–ö–∞—Ä—Ç–∏–Ω–æ–∫ –≤ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏:"),
            dcc.Input(id="images", type="number", value=4, min=0, max=12),
            html.Br(), html.Br(),
            dbc.Button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å", id="generate", color="primary"),
        ], width=6)
    ]),
    html.Br(),
    html.Div(id="output")
])

@app.callback(
    Output("output", "children"),
    Input("generate", "n_clicks"),
    State("topic", "value"),
    State("mode", "value"),
    State("detail", "value"),
    State("slides", "value"),
    State("images", "value"),
)
def run_generator(n, topic, mode, detail, slides, images):
    if not n:
        return ""
    text = get_clean_article(topic)
    if not text:
        return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—å—é —Å –í–∏–∫–∏–ø–µ–¥–∏–∏."

    intro = text[:400]
    conclusion = text[-400:]
    sections = split_into_sections(text, slides - 3)

    if mode in ["report", "both"]:
        generate_report(topic, intro, sections, conclusion)
    if mode in ["presentation", "both"]:
        image_urls = fetch_image_urls_bing(topic, images)
        generate_presentation(topic, intro, sections, conclusion, image_urls)

    return f"‚úÖ –ì–æ—Ç–æ–≤–æ! –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {topic}_report.docx –∏/–∏–ª–∏ {topic}_presentation.pptx"

if __name__ == "__main__":
    app.run_server(debug=True)